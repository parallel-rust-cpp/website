# More register reuse
[Full source][v5-rust]

In this version, we will re-organize our SIMD-packed data in a way that allows us to do more arithmetic operations on the data after it has been loaded into the CPU registers.
Recall how in the [previous implementation][self-v4] we performed 6 loads of `f32x8` vectors and computed 9 `f32x8` vectors worth of results in the performance critical loop.
Now, will perform 2 loads of `f32x8` vectors and compute 8 `f32x8` vectors worth of results.
This time, each `f32x8` will contain 8 elements from 8 different rows instead of 8 elements from the same row.
As usual, the columns of `vd` are the rows of `vt`.
For each pair of `f32x8` vectors from `vd` and `vt`, we will compute results for 8 different rows and 8 different columns, which means we can write 64 unique `f32` results into `r` after each pass.

The approach is explained in detail with nice visualizations in the [reference materials][ppc-v5].

## Implementation

We can keep most of the code from [`v4`][self-v4] as it is, but with some modifications.
First, we need to pack our SIMD vectors into a different order.
Fortunately, this is simply a matter of swapping some indexes.
Let's start by allocating some space for `vd` and `vt`.
Each row of `f32x8`s in `vd` corresponds to 8 rows of `d`, and each row of `f32x8`s in `vt` corresponds to 8 columns of `d`.
```rust,no_run,noplaypen
{{#include ../../shortcut-comparison/src/rust/v5_more_register_reuse/src/lib.rs:init}}
```
The preprocessing will be very similar to [`v4`][self-v4], but this time we pack 8 rows and 8 columns of `d` into `vd` and `vt`, vertically as `f32x8` vectors.
```rust,no_run,noplaypen
{{#include ../../shortcut-comparison/src/rust/v5_more_register_reuse/src/lib.rs:pack_simd}}
{{#include ../../shortcut-comparison/src/rust/v5_more_register_reuse/src/lib.rs:pack_simd_apply}}
```
Now all elements from `d` have been packed vertically into 8-row blocks.
Next, we will perform the `step` computations on all row blocks, such that the smallest unit of work for a thread is to compute 8 rows worth of results into `r`.
Before defining `step_row_block`, let's plan how we will divide the work into parallel threads.
Since one row of `f32x8`s in `vd` represents 8 rows of `d`, we will chunk `r` into blocks of 8 rows and chunk `vd` into single rows.
Then, we zip them up and apply `step_row_block` in parallel on all pairs:
```rust,no_run,noplaypen
{{#include ../../shortcut-comparison/src/rust/v5_more_register_reuse/src/lib.rs:step_row_block_header}}
        // ...
    };
{{#include ../../shortcut-comparison/src/rust/v5_more_register_reuse/src/lib.rs:step_row_block_apply}}
```
Now, for a 8-row block of `d` (`vd_row`), we need to compute `8n` results into `r` by iterating over all 8-column blocks of `d` (row `j` of `vt`).
```rust,no_run,noplaypen
{{#include ../../shortcut-comparison/src/rust/v5_more_register_reuse/src/lib.rs:step_row_block_init}}
            // ...
```
In the innermost loop, we loop over a pair of rows `vd_row` and `vt_row`.
For each pair of `f32x8` vectors, we will compute 3 different permutations of the vector elements for `vd_row` and 1 permutation for `vt_row`.
Then, combining all permuted `f32x8`s, we accumulate 64 unique results for 8 rows and 8 columns of `d`.
We'll define a helper function [`simd::swap`][simd-tools-rust-swap] for inserting intrinsic functions that permute the elements of a `f32x8`.
```rust,no_run,noplaypen
{{#include ../../shortcut-comparison/src/rust/v5_more_register_reuse/src/lib.rs:step_row_block_inner}}
```
When we are done with the loop, we need to take care when extracting results from the 8 intermediate `f32x8` results accumulated into `tmp` to make sure the indexes are mapped correctly back to `r`.
Since `tmp` contains 8 rows of `f32x8` vectors, we need to extract 64 `f32`s into a 8-by-8 block in `r`.
The tricky part is that we have to somehow undo all the permutations.

Let's use a fixed, two-dimensional indexing pattern for writing `f32`s into a 8-by-8 block in `r_row_block` and figure out later how to read from the correct indexes in `tmp`.
We chunk `r_row_block` into 8 rows of length `n` and enumerate the rows by `tmp_i`.
Then we iterate over 8 elements starting at `j * 8` of each row `tmp_i` in `r_row_block` and enumerate them by `tmp_j`, where `j` is the index of `vt_row` in `vt`.
Now we need to extract 64 `f32` results from `tmp` and write them to row `tmp_i` and column `tmp_j` in the sub-block of 64 `f32`s in `r_row_block`, while taking into account that the elements in `tmp` are permuted.

Consider [this][ppc-v5-png] figure, and the 8-by-8 block on the left which shows the indexes of all elements in `vv`, i.e. our `tmp`.
Blue indexes on the left side of the plus sign equals `tmp_i` and orange indexes on the right side of the plus sign equals `tmp_j`.
If we permute the elements of rows with odd indexes by [`simd::swap(v, 1)`][simd-tools-rust-swap], you can see that the `tmp_j` indexes will follow `0..8` on every row.
More importantly, we can now retrieve the result for row `tmp_i` at column `tmp_j` from `tmp` at row `tmp_i XOR tmp_j` from element `tmp_j`.

```rust,no_run,noplaypen
{{#include ../../shortcut-comparison/src/rust/v5_more_register_reuse/src/lib.rs:step_row_block_results}}
```

## Full `step_row_block` implementation

```rust,no_run,noplaypen
{{#include ../../shortcut-comparison/src/rust/v5_more_register_reuse/src/lib.rs:step_row_block}}
{{#include ../../shortcut-comparison/src/rust/v5_more_register_reuse/src/lib.rs:step_row_block_apply}}
```


## Benchmark

Let's run benchmarks with the same settings as before: `n = 6000`, single iteration, four threads bound to four cores.
C++ version available [here][v5-cpp].

Implementation | Compiler | Time (s) | IPC
:------|:---------|:---------|:---------------
C++ `v5` | `gcc 7.4.0-1ubuntu1` | 2.4 | 2.46
C++ `v5` | `clang 6.0.0-1ubuntu2` | 2.6 | 2.06
Rust `v5` | `rustc 1.38.0-nightly` | 2.5 | 2.54

The lower IPC for `clang` might be due to lower usage of CPUs (2.5 CPUs) than in other versions (3.5 CPUs).
The reason for this is still unclear.

## Assembly

All 3 compilers produced similar loops, which all load two `f32x8`s, perform 4 permutations, and compute 8 additions and 8 minimums.
One notable difference is that `gcc` performs all permutations using 32-bit and 128-bit lanes, while both `clang` and `rustc` load one register as double-precision floats and do permutations using 32-bit and 64-bit lanes.

### `gcc`
```x86asm
{{#include asm/v5_cpp_gcc.asm}}
```

### `clang`
```x86asm
{{#include asm/v5_cpp_clang.asm}}
```

### `rustc`
```x86asm
{{#include asm/v5_rs.asm}}
```

{{#include LINKS.md}}
