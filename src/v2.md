# Instruction level parallelism (ILP)
[Full source][v2-rust]

Our program does not take advantage of the fact that modern CPUs are [superscalar processors][wiki-superscalar], capable of executing several independent instructions simultaneously.
The problem in our [`v1`][self-v1] implementation is that each step is dependent on the previous step, caused by this part:
```rust,no_run,noplaypen
    let z = x + y;
    v = min(v, z);
```
We will solve this by using a simple idea from the [reference solution][ppc-v2]: accumulate results into 4 independent, intermediate results and merge them only after processing the whole row.

Suppose we have some row of `d`, containing the elements `x0, x1, x2, x3, ..., xn`, and some column of `d` (i.e. row of `t`), containing the elements `y0, y1, y2, y3, ..., yn`.
Then, we compute results for all rows by accumulating intermediate results into 4 variables `v0, v1, v2, v3` as follows:
```rust,no_run,noplaypen
    // iteration 1
    v0 = min(v0, x0 + y0);
    v1 = min(v1, x1 + y1);
    v2 = min(v2, x2 + y2);
    v3 = min(v3, x3 + y3);
    // iteration 2
    v0 = min(v0, x4 + y4);
    v1 = min(v1, x5 + y5);
    v2 = min(v2, x6 + y6);
    v3 = min(v3, x7 + y7);
    // iteration 3
    v0 = min(v0, x8 + y8);
    v1 = min(v1, x9 + y9);
    v2 = min(v2, x10 + y10);
    v3 = min(v3, x11 + y11);
    // etc ...
```

This should allow the CPU to write results into 4 independent registers for each intermediate result.

Before we can update the `step_row` function, we need to make sure the amount of elements on each row is always a multiple of 4 to keep the performance-critical loop free of messy, unnecessary branching.
As previously, we transpose `d` to allow linear reading of its columns, but have to make sure the row length of the transpose is also divisible by 4.
The preprocessing looks a bit more complicated, but is essentially the same as doing the transpose in [`v1`][self-v1], except that we copy the values of `d` also into `vd`, which is padded with `std::f32::INFINITY` values to make its rows divisible by 4:
```rust,no_run,noplaypen
{{#include ../../shortcut-comparison/src/rust/v2_instr_level_parallelism/src/lib.rs:preprocess}}
{{#include ../../shortcut-comparison/src/rust/v2_instr_level_parallelism/src/lib.rs:preprocess_apply}}
```

Now `vd` contains the original `d` and `vt` contains the transpose of `d`, but both have been padded with extra columns to the right containing `f32::INFINITY`s to ensure the width of `vd` and `vt` is always divisible by 4.
Then, we partition `r` and `vd` into row chunks, zip them into row chunk pairs and apply `step_row` in parallel for each row of `vd`, writing the results into its paired result row chunk.
Each thread will compute results over all rows of `vt`.
```rust,no_run,noplaypen
{{#include ../../shortcut-comparison/src/rust/v2_instr_level_parallelism/src/lib.rs:step_row}}
{{#include ../../shortcut-comparison/src/rust/v2_instr_level_parallelism/src/lib.rs:step_row_apply}}
```

## Benchmark

We'll now compare the Rust implementation to the reference [C++ version][v2-cpp], which will be compiled with both Clang and GCC.
If we run the benchmark program for a single iteration with the same parameters as previously, we get:

Implementation | Compiler | Time (s) | IPC
:------|:---------|:---------|:---------------
C++ `v2` | `gcc 7.4.0-1ubuntu1` | 20.8 | 2.88
C++ `v2` | `clang 6.0.0-1ubuntu2` | 44.6 | 3.23
Rust `v2` | `rustc 1.38.0-nightly` | 17.0 | 2.43

Two interesting questions arise:
* Why is `rustc` outperforming `gcc`?
* What on earth is `clang` doing?

Let's compare the disassembly of all 3 versions.

### `rustc`

I omitted a portion of code above `LOOP`, up until label `1f0` since [`perf-record`][perf-record-man] placed most CPU cycles between `LOOP` and the `jb` instruction that jumps to `LOOP`.

It looks like the compiler outsmarted us by ignoring our attempt of writing code that utilizes ILP and instead auto-vectorized our loop, which now does all the work with two 128-bit SIMD registers:
```x86asm
{{#include asm/v2_rs.asm}}
```
We'll be rewriting most of our code with 256-bit vector types and instructions in [`v3`][self-v3], but let's take a look at what the compiler managed to generate here.

We load 4 consecutive `f32` values from `vd_row` into a 128-bit vector register `xmm3`:
```x86asm
{{#include asm/v2_rs.asm:6}}
```
Then we load 4 consecutive `f32` values from `vt_row`, add those to the 4 values in `xmm3` using a single SIMD add-instruction, and store the result in `xmm3`:
```x86asm
{{#include asm/v2_rs.asm:7}}
```
Using `vpermilps` with shuffle control `0x1b = 0b00_01_10_11` will reverse the order of 4 elements in `xmm3`, but I don't know why the compiler wants to use this here, especially inside the loop.
However, we are going to use these kind of SIMD register permutations ourselves later in [`v5`][self-v5] to significantly lower the total amount of memory accesses.
```x86asm
{{#include asm/v2_rs.asm:8}}
```
We use a single SIMD min-instruction for 4 `f32` result values in `xmm2` and 4 sums in `xmm3` we got from the previous step and store the result in `xmm2`:
```x86asm
{{#include asm/v2_rs.asm:9}}
```
We increment the loop variable by 16, which will jump over 4 `f32`s in the next loop, and start over:
```x86asm
{{#include asm/v2_rs.asm:10:12}}
```

### `clang`
I did not try to figure out what happens here, but it looks like a failed auto-vectorization attempt:
```x86asm
{{#include asm/v2_cpp_clang.asm}}
```
### `gcc`
GCC did not auto-vectorize anything but produced a good example of ILP:
```x86asm
{{#include asm/v2_cpp_gcc.asm}}
```
This is what we were trying to achieve, to have 4 independent registers for updating the minimums.
You can read more about it [here][ppc-v2-asm].

We are not going to twist our Rust code so we can get a good ILP example out of it, the auto-vectorization already produced code that was more efficient than the `gcc` ILP example above.
However, this was just an example, and we'll be needing ILP extensively later in [`v4`][self-v4].
First, let's rewrite our code using SIMD instructions.

{{#include LINKS.md}}
